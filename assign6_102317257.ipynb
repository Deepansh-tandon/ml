{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55tIallam2Rt",
        "outputId": "79b00dd4-c959-468d-80f7-98560ea8af30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Gaussian Naive Bayes (From scratch) =====\n",
            "Test accuracy: 0.9211\n",
            "Confusion matrix (true x pred):\n",
            "[[12  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  2 11]]\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        12\n",
            "  versicolor       0.86      0.92      0.89        13\n",
            "   virginica       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.92        38\n",
            "   macro avg       0.92      0.92      0.92        38\n",
            "weighted avg       0.92      0.92      0.92        38\n",
            "\n",
            "===== Gaussian Naive Bayes (sklearn) =====\n",
            "Test accuracy: 0.9211\n",
            "Confusion matrix (true x pred):\n",
            "[[12  0  0]\n",
            " [ 0 12  1]\n",
            " [ 0  2 11]]\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        12\n",
            "  versicolor       0.86      0.92      0.89        13\n",
            "   virginica       0.92      0.85      0.88        13\n",
            "\n",
            "    accuracy                           0.92        38\n",
            "   macro avg       0.92      0.92      0.92        38\n",
            "weighted avg       0.92      0.92      0.92        38\n",
            "\n",
            "===== K-NN (GridSearchCV) =====\n",
            "Best K (n_neighbors): 10\n",
            "Best mean CV accuracy (on training folds): 0.9644\n",
            "Test accuracy with best K: 0.9737\n",
            "Confusion matrix (true x pred) for final KNN:\n",
            "[[12  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  1 12]]\n",
            "Classification report for final KNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        12\n",
            "  versicolor       0.93      1.00      0.96        13\n",
            "   virginica       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.97        38\n",
            "   macro avg       0.98      0.97      0.97        38\n",
            "weighted avg       0.98      0.97      0.97        38\n",
            "\n",
            "\n",
            "CV results (n_neighbors, mean_cv_test_score, std_cv_test_score, mean_cv_train_score):\n",
            "1 0.9549 0.0407 1.0000\n",
            "2 0.9375 0.0360 0.9843\n",
            "3 0.9549 0.0407 0.9620\n",
            "4 0.9285 0.0222 0.9687\n",
            "5 0.9549 0.0407 0.9709\n",
            "6 0.9462 0.0439 0.9732\n",
            "7 0.9640 0.0339 0.9732\n",
            "8 0.9549 0.0407 0.9777\n",
            "9 0.9640 0.0339 0.9732\n",
            "10 0.9644 0.0178 0.9777\n",
            "11 0.9644 0.0178 0.9799\n",
            "12 0.9466 0.0333 0.9732\n",
            "13 0.9553 0.0398 0.9799\n",
            "14 0.9375 0.0360 0.9799\n",
            "15 0.9636 0.0445 0.9777\n",
            "16 0.9553 0.0398 0.9710\n",
            "17 0.9553 0.0398 0.9754\n",
            "18 0.9466 0.0333 0.9687\n",
            "19 0.9466 0.0333 0.9687\n",
            "20 0.9466 0.0333 0.9665\n",
            "\n",
            "Saved files:\n",
            " - /content/knn_cv_plot.png\n",
            " - /content/classification_results_summary.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import os\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "PLOT_FILE = \"knn_cv_plot.png\"\n",
        "CSV_FILE = \"classification_results_summary.csv\"\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "class_names = iris.target_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "class GaussianNaiveBayes:\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        n_features = X.shape[1]\n",
        "        self.mean = np.zeros((len(self.classes), n_features))\n",
        "        self.var = np.zeros((len(self.classes), n_features))\n",
        "        self.prior = np.zeros(len(self.classes))\n",
        "        for idx, c in enumerate(self.classes):\n",
        "            X_c = X[y == c]\n",
        "            self.mean[idx, :] = X_c.mean(axis=0)\n",
        "            # ML estimate of variance (ddof=0)\n",
        "            self.var[idx, :] = X_c.var(axis=0)\n",
        "            self.prior[idx] = X_c.shape[0] / X.shape[0]\n",
        "        return self\n",
        "\n",
        "    def _gaussian_log_likelihood(self, class_idx, x):\n",
        "        mean = self.mean[class_idx]\n",
        "        var = self.var[class_idx]\n",
        "        # avoid division by zero\n",
        "        var = np.where(var == 0, 1e-9, var)\n",
        "        # log of gaussian pdf per feature\n",
        "        log_likelihood = -0.5 * np.log(2 * np.pi * var) - ((x - mean) ** 2) / (2 * var)\n",
        "        # sum over features\n",
        "        return log_likelihood.sum()\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for x in X:\n",
        "            posteriors = []\n",
        "            for idx, _ in enumerate(self.classes):\n",
        "                log_prior = np.log(self.prior[idx])\n",
        "                log_likelihood = self._gaussian_log_likelihood(idx, x)\n",
        "                posteriors.append(log_prior + log_likelihood)\n",
        "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
        "        return np.array(y_pred)\n",
        "\n",
        "\n",
        "gnb_scratch = GaussianNaiveBayes().fit(X_train, y_train)\n",
        "y_pred_scratch = gnb_scratch.predict(X_test)\n",
        "acc_scratch = accuracy_score(y_test, y_pred_scratch)\n",
        "cm_scratch = confusion_matrix(y_test, y_pred_scratch)\n",
        "report_scratch = classification_report(y_test, y_pred_scratch, target_names=class_names, zero_division=0)\n",
        "\n",
        "\n",
        "gnb_sklearn = GaussianNB().fit(X_train, y_train)\n",
        "y_pred_sklearn = gnb_sklearn.predict(X_test)\n",
        "acc_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "cm_sklearn = confusion_matrix(y_test, y_pred_sklearn)\n",
        "report_sklearn = classification_report(y_test, y_pred_sklearn, target_names=class_names, zero_division=0)\n",
        "\n",
        "\n",
        "param_grid = {'n_neighbors': list(range(1, 21))}\n",
        "knn = KNeighborsClassifier()\n",
        "grid = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy', return_train_score=True)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "best_k = int(grid.best_params_['n_neighbors'])\n",
        "best_score = float(grid.best_score_)\n",
        "\n",
        "cv_results = pd.DataFrame(grid.cv_results_)[\n",
        "    ['param_n_neighbors', 'mean_test_score', 'std_test_score', 'mean_train_score']\n",
        "].rename(columns={\n",
        "    'param_n_neighbors': 'n_neighbors',\n",
        "    'mean_test_score': 'mean_cv_test_score',\n",
        "    'std_test_score': 'std_cv_test_score',\n",
        "    'mean_train_score': 'mean_cv_train_score'\n",
        "}).sort_values('n_neighbors').reset_index(drop=True)\n",
        "# convert param objects to int if needed\n",
        "cv_results['n_neighbors'] = cv_results['n_neighbors'].apply(lambda v: int(v))\n",
        "\n",
        "# Train final KNN with best K and evaluate on test set\n",
        "knn_best = KNeighborsClassifier(n_neighbors=best_k).fit(X_train, y_train)\n",
        "y_pred_knn = knn_best.predict(X_test)\n",
        "acc_knn_test = accuracy_score(y_test, y_pred_knn)\n",
        "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "report_knn = classification_report(y_test, y_pred_knn, target_names=class_names, zero_division=0)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.errorbar(\n",
        "    cv_results['n_neighbors'].tolist(),\n",
        "    cv_results['mean_cv_test_score'].tolist(),\n",
        "    yerr=cv_results['std_cv_test_score'].tolist(),\n",
        "    marker='o', linestyle='-'\n",
        ")\n",
        "plt.title('K-NN: CV mean test accuracy vs K')\n",
        "plt.xlabel('K (n_neighbors)')\n",
        "plt.ylabel('Mean CV accuracy')\n",
        "plt.xticks(cv_results['n_neighbors'].tolist())\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(PLOT_FILE)\n",
        "plt.close()\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame([\n",
        "    ['GNB (scratch)', float(acc_scratch)],\n",
        "    ['GNB (sklearn)', float(acc_sklearn)],\n",
        "    [f'KNN (k={best_k})', float(acc_knn_test)]\n",
        "], columns=['model', 'test_accuracy'])\n",
        "results_df.to_csv(CSV_FILE, index=False)\n",
        "\n",
        "\n",
        "print(\"===== Gaussian Naive Bayes (From scratch) =====\")\n",
        "print(f\"Test accuracy: {acc_scratch:.4f}\")\n",
        "print(\"Confusion matrix (true x pred):\")\n",
        "print(cm_scratch)\n",
        "print(\"Classification report:\")\n",
        "print(report_scratch)\n",
        "\n",
        "print(\"===== Gaussian Naive Bayes (sklearn) =====\")\n",
        "print(f\"Test accuracy: {acc_sklearn:.4f}\")\n",
        "print(\"Confusion matrix (true x pred):\")\n",
        "print(cm_sklearn)\n",
        "print(\"Classification report:\")\n",
        "print(report_sklearn)\n",
        "\n",
        "print(\"===== K-NN (GridSearchCV) =====\")\n",
        "print(f\"Best K (n_neighbors): {best_k}\")\n",
        "print(f\"Best mean CV accuracy (on training folds): {best_score:.4f}\")\n",
        "print(f\"Test accuracy with best K: {acc_knn_test:.4f}\")\n",
        "print(\"Confusion matrix (true x pred) for final KNN:\")\n",
        "print(cm_knn)\n",
        "print(\"Classification report for final KNN:\")\n",
        "print(report_knn)\n",
        "\n",
        "print(\"\\nCV results (n_neighbors, mean_cv_test_score, std_cv_test_score, mean_cv_train_score):\")\n",
        "for _, row in cv_results.iterrows():\n",
        "    print(int(row['n_neighbors']),\n",
        "          f\"{row['mean_cv_test_score']:.4f}\",\n",
        "          f\"{row['std_cv_test_score']:.4f}\",\n",
        "          f\"{row['mean_cv_train_score']:.4f}\")\n",
        "\n",
        "print(f\"\\nSaved files:\\n - {os.path.abspath(PLOT_FILE)}\\n - {os.path.abspath(CSV_FILE)}\")\n"
      ]
    }
  ]
}